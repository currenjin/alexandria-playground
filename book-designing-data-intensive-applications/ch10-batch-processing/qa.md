### Q1. 배치 처리 vs 스트림 처리는 언제 각각 선택하나요?
A. 배치: 지연 허용(분~시간), 대량 처리, 복잡한 집계/조인, 재처리 용이. 스트림: 저지연 필요(초~분), 무한 데이터, 실시간 반응. 둘 다 필요하면 Lambda/Kappa 아키텍처.

### Q2. MapReduce가 느린 이유와 대안은?
A. 중간 결과를 디스크에 기록(셔플 I/O), 반복 연산에 비효율. 대안: Spark(메모리 캐싱, DAG 최적화), Flink(스트림 기반 배치). 단순 ETL은 MapReduce도 충분.

### Q3. 배치 작업의 멱등성은 어떻게 보장하나요?
A. 입력 불변 + 출력 덮어쓰기. 같은 입력 → 같은 출력. 출력 경로에 버전/날짜 포함. 부분 실패 시 전체 재실행. 외부 부작용(DB 쓰기)은 멱등 연산(UPSERT) 또는 트랜잭션 사용.

### Q4. 조인 전략(Sort-Merge, Broadcast, Partitioned)은 어떻게 선택하나요?
A. 한 쪽 작으면 Broadcast(메모리에 복제). 둘 다 크면 같은 키로 파티셔닝 후 Partitioned Join. 파티셔닝 안 맞으면 Sort-Merge(정렬 후 병합). 데이터 크기와 분포에 따라 선택.

### Q5. 데이터 스큐(Skew)는 어떻게 처리하나요?
A. 핫 키가 한 리듀서에 몰림. 해결: 핫 키 샘플링 후 솔팅(salting, 키에 랜덤 접미사), 별도 처리 후 병합. Spark의 skew join hint, 수동 파티션 조정.

### Q6. 배치 실패 시 복구 전략은?
A. 체크포인트에서 재시작 또는 전체 재실행(입력 불변이면 안전). 실패 원인 파악: 데이터 품질(bad record), 리소스 부족, 코드 버그. 실패 레코드 격리(bad record 파일) 후 나머지 진행 옵션.

### Q7. 배치 파이프라인 모니터링은 어떻게 하나요?
A. 작업 시작/종료 시간, 처리 레코드 수, 입출력 크기, 실패율. SLA: "D+1 06시까지 완료". 알람: 지연, 실패, 데이터 품질(레코드 수 이상). 계보(Lineage) 추적으로 의존성 파악.

### Q8. 배치 결과의 신선도(Freshness)는 어떻게 관리하나요?
A. 배치 주기가 신선도 상한. 일 배치 → 최대 24시간 지연. 마이크로 배치(Spark Structured Streaming)로 분 단위 가능. 실시간 필요하면 스트림 처리로 전환. 사용자 기대에 맞게 주기 조정.
