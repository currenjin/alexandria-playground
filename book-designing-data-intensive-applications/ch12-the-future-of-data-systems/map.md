# Ch12 The Future of Data Systems

## TL;DR (3문장)
- 미래 데이터 시스템은 **여러 저장소/처리 엔진을 조합**한다. 단일 만능 솔루션은 없다.
- **데이터 통합**은 CDC, 이벤트 로그, 파생 데이터로 이루어진다. 진실의 원천(Source of Truth)을 명확히.
- **정확성(Correctness)** 은 결국 end-to-end로 보장해야 한다. 멱등성, 제약, 감사로 불변식 지킨다.

## Key Ideas
- **데이터 통합 패턴**
  - CDC(Change Data Capture): DB 변경 → 이벤트 스트림
  - 이벤트 소싱: 상태 변경을 이벤트 시퀀스로 저장
  - 파생 데이터: 원천에서 읽기 최적화 뷰 생성
- **Unbundling the Database**
  - 전통 DB: 저장, 인덱싱, 쿼리, 트랜잭션 통합
  - 현대: 각 기능을 별도 시스템으로 분리 조합
  - 예: Kafka(로그) + Elasticsearch(검색) + Redis(캐시)
- **Lambda vs Kappa 아키텍처**
  - Lambda: 배치 + 스트림 이중 경로
  - Kappa: 스트림만(재처리는 리플레이)
- **End-to-End 정확성**
  - 시스템 경계에서 정확성 깨짐 가능
  - 클라이언트 → 서버 → DB → 이벤트 전체 경로 보장 필요
- **멱등성의 중요성**
  - 네트워크 불확실성 → 재시도 필연
  - 모든 쓰기 연산 멱등하게 설계
- **불변식 검증**
  - 제약(Constraint)으로 불변식 명시
  - 비동기 감사(Audit)로 사후 검증
- **신뢰와 검증**
  - 외부 입력 신뢰하지 않음
  - 모든 경계에서 검증
- **윤리와 개인정보**
  - 데이터 수집/사용의 윤리적 고려
  - 최소 수집, 목적 제한, 삭제 권리

## Trade-offs
| 선택 | 장점 | 단점 | 언제 |
|---|---|---|---|
| **단일 통합 DB** | 단순, 트랜잭션↑ | 확장 한계, 유연성↓ | 소규모, 단순 도메인 |
| **다중 저장소 조합** | 유연, 각 요구 최적화 | 일관성 관리 복잡 | 대규모, 다양한 접근 패턴 |
| **이벤트 소싱** | 감사↑, 시간여행, 디버깅 | 복잡, 쿼리 어려움 | 감사 필수, 이력 중요 |
| **CDC 기반 통합** | 기존 DB 유지, 점진 도입 | CDC 지연, 스키마 결합 | 레거시 현대화 |
| **Lambda 아키텍처** | 정확성(배치) + 저지연(스트림) | 이중 유지, 복잡 | 정확성과 지연 둘 다 중요 |
| **Kappa 아키텍처** | 단일 경로, 단순 | 재처리 비용, 스트림 한계 | 스트림만으로 충분한 경우 |
| **동기 제약 검증** | 즉시 차단 | 지연↑, 가용성↓ | 핵심 불변식 |
| **비동기 감사** | 가용성↑ | 사후 발견, 보상 필요 | 느슨한 정합 허용 |

## Apply to Our Domain (Orders/Dispatch)
- **데이터 통합 아키텍처**
  - 원천: 주문 DB(PostgreSQL)
  - CDC: Debezium → Kafka
  - 파생: Elasticsearch(검색), Redis(캐시), BigQuery(분석)
- **이벤트 소싱 검토**
  - 주문 상태 변경을 이벤트로 저장
  - 현재 상태 = 이벤트 시퀀스 리플레이
  - 감사 로그 자동화, 상태 복원 가능
- **End-to-End 멱등성**
  - 클라이언트: Idempotency-Key 헤더
  - 서버: 키 저장(24h TTL), 중복 요청 동일 응답
  - 이벤트: 소비자별 처리 기록(exactly-once 효과)
- **불변식 검증**
  - 동기: DB UNIQUE, CHECK 제약
  - 비동기: 일일 감사 배치(잔액 불일치, 중복 배차 등)
- **Kappa 아키텍처 적용**
  - 스트림 처리로 읽기 모델 갱신
  - 재처리 = Kafka 리플레이(오프셋 리셋)

## Metrics & SLO (30일 롤링)
### SLI
- `cdc.lag_ms.p95`: CDC 지연
- `derived.freshness_ms.p95`: 파생 데이터 신선도
- `audit.violation_count`: 감사에서 발견된 불변식 위반 수
- `idempotency.dedup_rate`: 멱등키 중복 차단 비율
- `e2e.consistency_check.pass_rate`: End-to-End 일관성 검증 통과율

### SLO
- `cdc.lag_ms.p95 < 5000`
- `derived.freshness_ms.p95 < 10000`
- `audit.violation_count = 0` (목표)
- `e2e.consistency_check.pass_rate >= 99.99%`

## Open Questions
- **이벤트 소싱** 전면 도입 시 쿼리 복잡도와 성능 영향은?
- CDC 장애 시 **파생 데이터 정합성** 복구 전략은?
- **Lambda vs Kappa** 중 우리 도메인에 더 적합한 아키텍처는?
- End-to-End **멱등성 보장 범위**를 어디까지 확장할 것인가? (외부 결제, 알림 등)
- 데이터 삭제 요청(GDPR 등) 시 **이벤트 로그 처리** 전략은?

## Hands-on
### 실험 목표
- CDC 기반 파생 데이터 파이프라인의 End-to-End 정확성과 신선도를 검증한다.

### 준비
- 원천 DB + CDC 커넥터 + 메시지 브로커 + 파생 저장소 1종
- 샘플 불변식(예: 주문 상태 전이 규칙, 중복 주문 금지)

### 실행 단계
1. 원천 DB에 주문 생성/취소/변경 이벤트를 순차 주입한다.
2. 파생 저장소 반영 지연(`freshness`)을 측정한다.
3. 동일 이벤트를 중복 재전송해 멱등 처리 여부를 확인한다.
4. 일괄 감사 배치로 원천-파생 불일치 건수를 집계한다.

### 검증 메트릭
- `cdc.lag_ms.p95`
- `derived.freshness_ms.p95`
- `idempotency.dedup_rate`
- `audit.violation_count`

### 실패 시 체크포인트
- 불일치 발생 시 재처리(runbook)로 복구 가능 여부 우선 검증
- CDC 중단 시 재시작 오프셋/스냅샷 전략 점검
